{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Neural Networks to NBA Team Win Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to hold all dataset names\n",
    "dataset_list = []\n",
    "\n",
    "# adds all CSV files from the datasets folder to a list\n",
    "for dataset in os.listdir('./win_predictor_data/'):\n",
    "    if (dataset.endswith('.csv')):\n",
    "        dataset_list.append(dataset)\n",
    "\n",
    "# adds all datasets to a dictionary with the key being 'Year Type' \n",
    "datasets = {}\n",
    "for dataset in dataset_list:\n",
    "    data_file = pd.read_csv('./win_predictor_data/' + dataset)\n",
    "    dataset_name = dataset[dataset.index('- ') + 1 : dataset.index('.')].strip()\n",
    "    datasets[dataset_name] = data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove asterisks from team names\n",
    "def remove_asterisk(team):\n",
    "    if team.endswith(\"*\"):\n",
    "        return team[0:len(team)-1]\n",
    "    return team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_training_data(datasets):\n",
    "    \"\"\"\n",
    "    Creates the training data using the basketball datasets\n",
    "    @param datasets: A dictionary with year name & stat types as key and value of a pandas dataframe \n",
    "                         containing all the data \n",
    "    @return the training data and training data labels \n",
    "    \"\"\"\n",
    "    # create dictionary to hold aggregated datasets by year containing all (agg_datasets['2015-2016'])\n",
    "    agg_datasets = {}\n",
    "\n",
    "    # All the unwanted columns that won't be used in our neural network \n",
    "    unwanted_data = ['Rk_x', 'Team', 'Age', 'PW', 'PL', 'MOV', 'SOS', 'SRS', 'L', 'Arena', 'Attend.', 'Attend./G', 'Rk_y']\n",
    "\n",
    "    # run through each dataset and add to dictionary\n",
    "    for dataset in sorted(datasets):\n",
    "\n",
    "        # separate year\n",
    "        year_label = dataset[0 : dataset.index(' ')]\n",
    "\n",
    "        # remove asterisk from given dataset\n",
    "        datasets[dataset]['Team'] = datasets[dataset]['Team'].apply(remove_asterisk)\n",
    "\n",
    "        # add dataset to agg_datasets dictionary\n",
    "        if year_label in agg_datasets:\n",
    "            agg_datasets[year_label] = pd.merge(agg_datasets[year_label], datasets[dataset], on='Team')\n",
    "        else:\n",
    "            agg_datasets[year_label] = datasets[dataset]\n",
    "\n",
    "    # Aggregate all the data into one data frame and drop the unwanted features \n",
    "    agg_all_sets = pd.concat([agg_datasets[year_label] for year_label in agg_datasets], ignore_index = True)\n",
    "    agg_all_sets = agg_all_sets.drop(unwanted_data, axis = 1)\n",
    "\n",
    "\n",
    "    # Convert the aggregated data into a training set \n",
    "    training_data = [agg_all_sets.loc[i,:] for i in range(len(agg_all_sets))]\n",
    "    training_data = [team[1:] for team in training_data]\n",
    "\n",
    "    # Get the training data labels (Wins) from the training_data \n",
    "    training_data_labels = [team[0] for team in training_data]\n",
    "\n",
    "    return torch.tensor(training_data), torch.tensor(training_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_examples, num_features):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_size =  math.floor((2/3) * num_features) # 2/3 * 38 = 25\n",
    "        self.l1 = nn.Linear(num_features, hidden_size) # 38, 25\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size) # 25, 25\n",
    "        self.l3 = nn.Linear(hidden_size, 1) # 25, 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2252],\n",
       "        [-0.3540],\n",
       "        [-0.0819],\n",
       "        [ 0.0275],\n",
       "        [-0.2229],\n",
       "        [-0.1470],\n",
       "        [-0.0116],\n",
       "        [-0.0879],\n",
       "        [ 0.0507],\n",
       "        [ 0.1380],\n",
       "        [ 0.0421],\n",
       "        [ 0.0249],\n",
       "        [ 0.1374],\n",
       "        [ 0.2695],\n",
       "        [ 0.1618],\n",
       "        [ 0.1131],\n",
       "        [ 0.1789],\n",
       "        [ 0.0788],\n",
       "        [ 0.1225],\n",
       "        [ 0.0280],\n",
       "        [ 0.2633],\n",
       "        [ 0.1425],\n",
       "        [ 0.3031],\n",
       "        [ 0.1350],\n",
       "        [ 0.2498],\n",
       "        [ 0.1614],\n",
       "        [ 0.5842],\n",
       "        [ 0.4715],\n",
       "        [ 0.4172],\n",
       "        [ 0.5320],\n",
       "        [-0.3303],\n",
       "        [-0.2013],\n",
       "        [ 0.0712],\n",
       "        [-0.0828],\n",
       "        [ 0.0800],\n",
       "        [-0.2289],\n",
       "        [ 0.0427],\n",
       "        [-0.0035],\n",
       "        [-0.0374],\n",
       "        [ 0.2253],\n",
       "        [ 0.0448],\n",
       "        [ 0.0607],\n",
       "        [ 0.2971],\n",
       "        [ 0.1382],\n",
       "        [ 0.1192],\n",
       "        [ 0.0319],\n",
       "        [ 0.0612],\n",
       "        [-0.0085],\n",
       "        [ 0.1104],\n",
       "        [ 0.3335],\n",
       "        [ 0.2568],\n",
       "        [ 0.1178],\n",
       "        [ 0.2060],\n",
       "        [ 0.2508],\n",
       "        [ 0.1623],\n",
       "        [ 0.2237],\n",
       "        [ 0.4450],\n",
       "        [ 0.4348],\n",
       "        [ 0.3879],\n",
       "        [ 0.4887],\n",
       "        [-0.0087],\n",
       "        [-0.2121],\n",
       "        [-0.0647],\n",
       "        [ 0.1499],\n",
       "        [ 0.2429],\n",
       "        [ 0.0828],\n",
       "        [ 0.1234],\n",
       "        [ 0.0577],\n",
       "        [ 0.0604],\n",
       "        [-0.1353],\n",
       "        [ 0.2019],\n",
       "        [ 0.0707],\n",
       "        [ 0.0293],\n",
       "        [ 0.1480],\n",
       "        [ 0.1530],\n",
       "        [ 0.1717],\n",
       "        [ 0.2177],\n",
       "        [ 0.2054],\n",
       "        [ 0.2632],\n",
       "        [-0.0207],\n",
       "        [ 0.3588],\n",
       "        [ 0.2894],\n",
       "        [ 0.2688],\n",
       "        [ 0.3669],\n",
       "        [ 0.3473],\n",
       "        [ 0.4808],\n",
       "        [ 0.3571],\n",
       "        [ 0.4071],\n",
       "        [ 0.5923],\n",
       "        [ 0.5604],\n",
       "        [ 0.0280],\n",
       "        [-0.0753],\n",
       "        [-0.0899],\n",
       "        [ 0.1766],\n",
       "        [-0.1424],\n",
       "        [-0.0035],\n",
       "        [ 0.1298],\n",
       "        [-0.0394],\n",
       "        [-0.0121],\n",
       "        [-0.0258],\n",
       "        [ 0.1415],\n",
       "        [-0.0212],\n",
       "        [-0.0628],\n",
       "        [ 0.2340],\n",
       "        [ 0.2255],\n",
       "        [ 0.3395],\n",
       "        [ 0.2413],\n",
       "        [ 0.0891],\n",
       "        [ 0.3445],\n",
       "        [ 0.0455],\n",
       "        [ 0.2156],\n",
       "        [ 0.1008],\n",
       "        [ 0.3257],\n",
       "        [ 0.2143],\n",
       "        [ 0.1513],\n",
       "        [ 0.4480],\n",
       "        [ 0.3910],\n",
       "        [ 0.3066],\n",
       "        [ 0.4398],\n",
       "        [ 0.5042]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the training data into tensors \n",
    "training_data, training_data_labels = create_training_data(datasets)\n",
    "net = Net(len(training_data), len(training_data[0]))\n",
    "out = net(training_data.float())\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([25, 38])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (l1): Linear(in_features=38, out_features=25, bias=True)\n",
       "  (l2): Linear(in_features=25, out_features=25, bias=True)\n",
       "  (l3): Linear(in_features=25, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the neural network\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01) # stochastic gradient descent optimization function\n",
    "criterion = nn.MSELoss() # mean squared error loss function\n",
    "params = list(net.parameters()) # dimensions of the layers within the neural network\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(train)\n",
    "    \n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(120, 1),retain_graph=True)\n",
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = training_data_labels.float()\n",
    "target = target.view(-1, 1)\n",
    "loss = criterion(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "criterion = nn.MSELoss()\n",
    "loss.backward(retain_graph=True)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4856],\n",
       "        [-3.6997],\n",
       "        [-3.8999],\n",
       "        [-3.3356],\n",
       "        [-3.4191],\n",
       "        [-3.5719],\n",
       "        [-3.2878],\n",
       "        [-3.5360],\n",
       "        [-3.2956],\n",
       "        [-3.4602],\n",
       "        [-3.5641],\n",
       "        [-3.7366],\n",
       "        [-3.4206],\n",
       "        [-3.4939],\n",
       "        [-3.3873],\n",
       "        [-3.2386],\n",
       "        [-3.4685],\n",
       "        [-3.6042],\n",
       "        [-3.5117],\n",
       "        [-3.5848],\n",
       "        [-3.6501],\n",
       "        [-3.5161],\n",
       "        [-3.5415],\n",
       "        [-3.7851],\n",
       "        [-3.4437],\n",
       "        [-3.6772],\n",
       "        [-3.4404],\n",
       "        [-3.4564],\n",
       "        [-3.3511],\n",
       "        [-3.2361],\n",
       "        [-3.5050],\n",
       "        [-3.5300],\n",
       "        [-3.1970],\n",
       "        [-3.4562],\n",
       "        [-3.3547],\n",
       "        [-3.5847],\n",
       "        [-3.1710],\n",
       "        [-3.1605],\n",
       "        [-3.5531],\n",
       "        [-3.7012],\n",
       "        [-3.3401],\n",
       "        [-3.3795],\n",
       "        [-3.5180],\n",
       "        [-3.5502],\n",
       "        [-3.2611],\n",
       "        [-3.4895],\n",
       "        [-3.3966],\n",
       "        [-3.4757],\n",
       "        [-3.6244],\n",
       "        [-3.4552],\n",
       "        [-3.4400],\n",
       "        [-3.3570],\n",
       "        [-2.8466],\n",
       "        [-3.3820],\n",
       "        [-3.4799],\n",
       "        [-3.8327],\n",
       "        [-3.2684],\n",
       "        [-3.4135],\n",
       "        [-3.3201],\n",
       "        [-3.3133],\n",
       "        [-3.0164],\n",
       "        [-3.4269],\n",
       "        [-3.5026],\n",
       "        [-3.2980],\n",
       "        [-3.5428],\n",
       "        [-3.4033],\n",
       "        [-3.2211],\n",
       "        [-3.4383],\n",
       "        [-3.4277],\n",
       "        [-3.5920],\n",
       "        [-3.3442],\n",
       "        [-3.5294],\n",
       "        [-3.3673],\n",
       "        [-3.2343],\n",
       "        [-3.4277],\n",
       "        [-3.5360],\n",
       "        [-3.2185],\n",
       "        [-3.4832],\n",
       "        [-3.1765],\n",
       "        [-3.4836],\n",
       "        [-3.5203],\n",
       "        [-2.9099],\n",
       "        [-3.5211],\n",
       "        [-3.1097],\n",
       "        [-3.1758],\n",
       "        [-3.0676],\n",
       "        [-3.2575],\n",
       "        [-3.1738],\n",
       "        [-3.0496],\n",
       "        [-3.3980],\n",
       "        [-3.3819],\n",
       "        [-3.3836],\n",
       "        [-3.4073],\n",
       "        [-3.4541],\n",
       "        [-2.8590],\n",
       "        [-3.6094],\n",
       "        [-3.3601],\n",
       "        [-3.2100],\n",
       "        [-3.5816],\n",
       "        [-3.4337],\n",
       "        [-3.6892],\n",
       "        [-3.5372],\n",
       "        [-3.8112],\n",
       "        [-3.2147],\n",
       "        [-3.3479],\n",
       "        [-3.2376],\n",
       "        [-3.2092],\n",
       "        [-3.4430],\n",
       "        [-3.1562],\n",
       "        [-3.4927],\n",
       "        [-3.6066],\n",
       "        [-3.2090],\n",
       "        [-3.5155],\n",
       "        [-3.3050],\n",
       "        [-3.3440],\n",
       "        [-3.2786],\n",
       "        [-3.3730],\n",
       "        [-3.3609],\n",
       "        [-3.2960],\n",
       "        [-3.1375]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDos\n",
    "- Convert Data into Proper Format of Neural Net\n",
    "- Research Neural Network architectures for predictions (watch tutorials/videos)\n",
    "- set up PyTorch/Keras Framework to create neural network\n",
    "- EDA (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
